{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNphEnK0yMVAGhoReswxWAE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMKmU5A_LlqR",
        "outputId": "6ef227e0-e562-4a08-da8c-d36107629825"
      },
      "source": [
        "!pip install scipy==1.1.0 \n",
        "!pip install Keras==2.1.2\n",
        "!pip install Tensorflow==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n",
            "Requirement already satisfied: Keras==2.1.2 in /usr/local/lib/python3.7/dist-packages (2.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras==2.1.2) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras==2.1.2) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras==2.1.2) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras==2.1.2) (1.15.0)\n",
            "Requirement already satisfied: Tensorflow==1.15.0 in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (0.37.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (1.39.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from Tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->Tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->Tensorflow==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->Tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->Tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->Tensorflow==1.15.0) (4.6.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->Tensorflow==1.15.0) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->Tensorflow==1.15.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->Tensorflow==1.15.0) (3.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au9v2b6_B9_j",
        "outputId": "0abcc907-f34a-48b1-d428-848352ab2f9e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGHDsG0VFxzK",
        "outputId": "7c3dbe75-b9c8-4356-9eb5-d67829ad6132"
      },
      "source": [
        "cd \"/content/gdrive/MyDrive/datasets/img_align_celeba\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/datasets/img_align_celeba\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCasGf1RFvWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45137063-500e-46d8-9c98-57500351dea0"
      },
      "source": [
        "!unzip -qq \"/content/gdrive/MyDrive/datasets/img_align_celeba.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace 000001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqMnuLgHBRhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb91189-1472-4b81-bcee-bd06d5a26150"
      },
      "source": [
        "import glob\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import Input\n",
        "from keras.applications import VGG19\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import BatchNormalization, Activation, LeakyReLU, Add, Dense\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from scipy.misc import imread, imresize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0g9JR2aBasT"
      },
      "source": [
        "def residual_block(x):\n",
        "    \"\"\"\n",
        "    Residual block\n",
        "    \"\"\"\n",
        "    filters = [64, 64]\n",
        "    kernel_size = 3\n",
        "    strides = 1\n",
        "    padding = \"same\"\n",
        "    momentum = 0.8\n",
        "    activation = \"relu\"\n",
        "\n",
        "    res = Conv2D(filters=filters[0], kernel_size=kernel_size, strides=strides, padding=padding)(x)\n",
        "    res = Activation(activation=activation)(res)\n",
        "    res = BatchNormalization(momentum=momentum)(res)\n",
        "\n",
        "    res = Conv2D(filters=filters[1], kernel_size=kernel_size, strides=strides, padding=padding)(res)\n",
        "    res = BatchNormalization(momentum=momentum)(res)\n",
        "\n",
        "    # Add res and x\n",
        "    res = Add()([res, x])\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_99Yu51BcbS"
      },
      "source": [
        "def build_generator():\n",
        "    \"\"\"\n",
        "    Create a generator network using the hyperparameter values defined below\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    residual_blocks = 16\n",
        "    momentum = 0.8\n",
        "    input_shape = (64, 64, 3)\n",
        "\n",
        "    # Input Layer of the generator network\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Add the pre-residual block\n",
        "    gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same', activation='relu')(input_layer)\n",
        "\n",
        "    # Add 16 residual blocks\n",
        "    res = residual_block(gen1)\n",
        "    for i in range(residual_blocks - 1):\n",
        "        res = residual_block(res)\n",
        "\n",
        "    # Add the post-residual block\n",
        "    gen2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(res)\n",
        "    gen2 = BatchNormalization(momentum=momentum)(gen2)\n",
        "\n",
        "    # Take the sum of the output from the pre-residual block(gen1) and the post-residual block(gen2)\n",
        "    gen3 = Add()([gen2, gen1])\n",
        "\n",
        "    # Add an upsampling block\n",
        "    gen4 = UpSampling2D(size=2)(gen3)\n",
        "    gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n",
        "    gen4 = Activation('relu')(gen4)\n",
        "\n",
        "    # Add another upsampling block\n",
        "    gen5 = UpSampling2D(size=2)(gen4)\n",
        "    gen5 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen5)\n",
        "    gen5 = Activation('relu')(gen5)\n",
        "\n",
        "    # Output convolution layer\n",
        "    gen6 = Conv2D(filters=3, kernel_size=9, strides=1, padding='same')(gen5)\n",
        "    output = Activation('tanh')(gen6)\n",
        "\n",
        "    # Keras model\n",
        "    model = Model(inputs=[input_layer], outputs=[output], name='generator')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIMDmcUCBdkE"
      },
      "source": [
        "def build_discriminator():\n",
        "    \"\"\"\n",
        "    Create a discriminator network using the hyperparameter values defined below\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    leakyrelu_alpha = 0.2\n",
        "    momentum = 0.8\n",
        "    input_shape = (256, 256, 3)\n",
        "\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Add the first convolution block\n",
        "    dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
        "    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n",
        "\n",
        "    # Add the 2nd convolution block\n",
        "    dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n",
        "    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n",
        "    dis2 = BatchNormalization(momentum=momentum)(dis2)\n",
        "\n",
        "    # Add the third convolution block\n",
        "    dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n",
        "    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n",
        "    dis3 = BatchNormalization(momentum=momentum)(dis3)\n",
        "\n",
        "    # Add the fourth convolution block\n",
        "    dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n",
        "    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n",
        "    dis4 = BatchNormalization(momentum=0.8)(dis4)\n",
        "\n",
        "    # Add the fifth convolution block\n",
        "    dis5 = Conv2D(256, kernel_size=3, strides=1, padding='same')(dis4)\n",
        "    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n",
        "    dis5 = BatchNormalization(momentum=momentum)(dis5)\n",
        "\n",
        "    # Add the sixth convolution block\n",
        "    dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n",
        "    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n",
        "    dis6 = BatchNormalization(momentum=momentum)(dis6)\n",
        "\n",
        "    # Add the seventh convolution block\n",
        "    dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n",
        "    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n",
        "    dis7 = BatchNormalization(momentum=momentum)(dis7)\n",
        "\n",
        "    # Add the eight convolution block\n",
        "    dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n",
        "    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n",
        "    dis8 = BatchNormalization(momentum=momentum)(dis8)\n",
        "\n",
        "    # Add a dense layer\n",
        "    dis9 = Dense(units=1024)(dis8)\n",
        "    dis9 = LeakyReLU(alpha=0.2)(dis9)\n",
        "\n",
        "    # Last dense layer - for classification\n",
        "    output = Dense(units=1, activation='sigmoid')(dis9)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[output], name='discriminator')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDFOXUruBdey"
      },
      "source": [
        "def build_vgg():\n",
        "    \"\"\"\n",
        "    Build VGG network to extract image features\n",
        "    \"\"\"\n",
        "    input_shape = (256, 256, 3)\n",
        "\n",
        "    # Load a pre-trained VGG19 model trained on 'Imagenet' dataset\n",
        "    vgg = VGG19(weights=\"imagenet\")\n",
        "    vgg.outputs = [vgg.layers[9].output]\n",
        "\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Extract features\n",
        "    features = vgg(input_layer)\n",
        "\n",
        "    # Create a Keras model\n",
        "    model = Model(inputs=[input_layer], outputs=[features])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h06zWR9ZzyK9"
      },
      "source": [
        "def sample_images(data_dir, batch_size, high_resolution_shape, low_resolution_shape):\n",
        "    # Make a list of all images inside the data directory\n",
        "    all_images = glob.glob(data_dir)\n",
        "\n",
        "    # Choose a random batch of images\n",
        "    images_batch = np.random.choice(all_images, size=batch_size)\n",
        "\n",
        "    low_resolution_images = []\n",
        "    high_resolution_images = []\n",
        "\n",
        "    for img in images_batch:\n",
        "        # Get an ndarray of the current image\n",
        "        img1 = imread(img, mode='RGB')\n",
        "        img1 = img1.astype(np.float32)\n",
        "\n",
        "        # Resize the image\n",
        "        img1_high_resolution = imresize(img1, high_resolution_shape)\n",
        "        img1_low_resolution = imresize(img1, low_resolution_shape)\n",
        "\n",
        "        # Do a random horizontal flip\n",
        "        if np.random.random() < 0.5:\n",
        "            img1_high_resolution = np.fliplr(img1_high_resolution)\n",
        "            img1_low_resolution = np.fliplr(img1_low_resolution)\n",
        "\n",
        "        high_resolution_images.append(img1_high_resolution)\n",
        "        low_resolution_images.append(img1_low_resolution)\n",
        "\n",
        "    # Convert the lists to Numpy NDArrays\n",
        "    return np.array(high_resolution_images), np.array(low_resolution_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5IdRC66BdZC"
      },
      "source": [
        "def save_images(low_resolution_image, original_image, generated_image, path):\n",
        "    \"\"\"\n",
        "    Save low-resolution, high-resolution(original) and\n",
        "    generated high-resolution images in a single image\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 3, 1)\n",
        "    ax.imshow(low_resolution_image)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Low-resolution\")\n",
        "\n",
        "    ax = fig.add_subplot(1, 3, 2)\n",
        "    ax.imshow(original_image)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Original\")\n",
        "\n",
        "    ax = fig.add_subplot(1, 3, 3)\n",
        "    ax.imshow(generated_image)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Generated\")\n",
        "\n",
        "    plt.savefig(path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWWmuvD3BdSy"
      },
      "source": [
        "def write_log(callback, name, value, batch_no):\n",
        "    \"\"\"\n",
        "    Write scalars to Tensorboard\n",
        "    \"\"\"\n",
        "    summary = tf.Summary()\n",
        "    summary_value = summary.value.add()\n",
        "    summary_value.simple_value = value\n",
        "    summary_value.tag = name\n",
        "    callback.writer.add_summary(summary, batch_no)\n",
        "    callback.writer.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnxPk22UBdLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01342d36-d0a5-4e50-aff5-39110bb3a644"
      },
      "source": [
        "    data_dir = \"/content/gdrive/MyDrive/datasets/img_align_celeba/*.*\"\n",
        "    epochs = 500\n",
        "    batch_size = 32\n",
        "    mode = 'train'\n",
        "\n",
        "    # Shape of low-resolution and high-resolution images\n",
        "    low_resolution_shape = (64, 64, 3)\n",
        "    high_resolution_shape = (256, 256, 3)\n",
        "\n",
        "    # Common optimizer for all networks\n",
        "    common_optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "    if mode == 'train':\n",
        "        # Build and compile VGG19 network to extract features\n",
        "        vgg = build_vgg()\n",
        "        vgg.trainable = False\n",
        "        vgg.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n",
        "\n",
        "        # Build and compile the discriminator network\n",
        "        discriminator = build_discriminator()\n",
        "        discriminator.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator network\n",
        "        generator = build_generator()\n",
        "\n",
        "        \"\"\"\n",
        "        Build and compile the adversarial model\n",
        "        \"\"\"\n",
        "\n",
        "        # Input layers for high-resolution and low-resolution images\n",
        "        input_high_resolution = Input(shape=high_resolution_shape)\n",
        "        input_low_resolution = Input(shape=low_resolution_shape)\n",
        "\n",
        "        # Generate high-resolution images from low-resolution images\n",
        "        generated_high_resolution_images = generator(input_low_resolution)\n",
        "\n",
        "        # Extract feature maps of the generated images\n",
        "        features = vgg(generated_high_resolution_images)\n",
        "\n",
        "        # Make the discriminator network as non-trainable\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        # Get the probability of generated high-resolution images\n",
        "        probs = discriminator(generated_high_resolution_images)\n",
        "\n",
        "        # Create and compile an adversarial model\n",
        "        adversarial_model = Model([input_low_resolution, input_high_resolution], [probs, features])\n",
        "        adversarial_model.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=common_optimizer)\n",
        "\n",
        "        # Add Tensorboard\n",
        "        tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
        "        tensorboard.set_model(generator)\n",
        "        tensorboard.set_model(discriminator)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:{}\".format(epoch))\n",
        "\n",
        "            \"\"\"\n",
        "            Train the discriminator network\n",
        "            \"\"\"\n",
        "\n",
        "            # Sample a batch of images\n",
        "            high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
        "                                                                          low_resolution_shape=low_resolution_shape,\n",
        "                                                                          high_resolution_shape=high_resolution_shape)\n",
        "            # Normalize images\n",
        "            high_resolution_images = high_resolution_images / 127.5 - 1.\n",
        "            low_resolution_images = low_resolution_images / 127.5 - 1.\n",
        "\n",
        "            # Generate high-resolution images from low-resolution images\n",
        "            generated_high_resolution_images = generator.predict(low_resolution_images)\n",
        "\n",
        "            # Generate batch of real and fake labels\n",
        "            real_labels = np.ones((batch_size, 16, 16, 1))\n",
        "            fake_labels = np.zeros((batch_size, 16, 16, 1))\n",
        "\n",
        "            # Train the discriminator network on real and fake images\n",
        "            d_loss_real = discriminator.train_on_batch(high_resolution_images, real_labels)\n",
        "            d_loss_fake = discriminator.train_on_batch(generated_high_resolution_images, fake_labels)\n",
        "\n",
        "            # Calculate total discriminator loss\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "            print(\"d_loss:\", d_loss)\n",
        "\n",
        "            \"\"\"\n",
        "            Train the generator network\n",
        "            \"\"\"\n",
        "\n",
        "            # Sample a batch of images\n",
        "            high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
        "                                                                          low_resolution_shape=low_resolution_shape,\n",
        "                                                                          high_resolution_shape=high_resolution_shape)\n",
        "            # Normalize images\n",
        "            high_resolution_images = high_resolution_images / 127.5 - 1.\n",
        "            low_resolution_images = low_resolution_images / 127.5 - 1.\n",
        "\n",
        "            # Extract feature maps for real high-resolution images\n",
        "            image_features = vgg.predict(high_resolution_images)\n",
        "\n",
        "            # Train the generator network\n",
        "            g_loss = adversarial_model.train_on_batch([low_resolution_images, high_resolution_images],\n",
        "                                             [real_labels, image_features])\n",
        "\n",
        "            print(\"g_loss:\", g_loss)\n",
        "\n",
        "            # Write the losses to Tensorboard\n",
        "            write_log(tensorboard, 'g_loss', g_loss[0], epoch)\n",
        "            write_log(tensorboard, 'd_loss', d_loss[0], epoch)\n",
        "\n",
        "            # Sample and save images after every 100 epochs\n",
        "            if epoch % 100 == 0:\n",
        "                high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
        "                                                                              low_resolution_shape=low_resolution_shape,\n",
        "                                                                              high_resolution_shape=high_resolution_shape)\n",
        "                # Normalize images\n",
        "                high_resolution_images = high_resolution_images / 127.5 - 1.\n",
        "                low_resolution_images = low_resolution_images / 127.5 - 1.\n",
        "\n",
        "                generated_images = generator.predict_on_batch(low_resolution_images)\n",
        "\n",
        "                for index, img in enumerate(generated_images):\n",
        "                    save_images(low_resolution_images[index], high_resolution_images[index], img,\n",
        "                                path=\"/content/gdrive/MyDrive/datasets/result/img_{}_{}\".format(epoch, index))\n",
        "\n",
        "        # Save models\n",
        "        generator.save_weights(\"/content/gdrive/MyDrive/datasets/generator.h5\")\n",
        "        discriminator.save_weights(\"/content/gdrive/MyDrive/datasets/discriminator.h5\")\n",
        "\n",
        "    if mode == 'predict':\n",
        "        # Build and compile the discriminator network\n",
        "        discriminator = build_discriminator()\n",
        "\n",
        "        # Build the generator network\n",
        "        generator = build_generator()\n",
        "\n",
        "        # Load models\n",
        "        generator.load_weights(\"/content/gdrive/MyDrive/datasets/generator.h5\")\n",
        "        discriminator.load_weights(\"/content/gdrive/MyDrive/datasets/discriminator.h5\")\n",
        "\n",
        "        # Get 10 random images\n",
        "        high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=10,\n",
        "                                                                      low_resolution_shape=low_resolution_shape,\n",
        "                                                                      high_resolution_shape=high_resolution_shape)\n",
        "        # Normalize images\n",
        "        high_resolution_images = high_resolution_images / 127.5 - 1.\n",
        "        low_resolution_images = low_resolution_images / 127.5 - 1.\n",
        "\n",
        "        # Generate high-resolution images from low-resolution images\n",
        "        generated_images = generator.predict_on_batch(low_resolution_images)\n",
        "\n",
        "        # Save images\n",
        "        for index, img in enumerate(generated_images):\n",
        "            save_images(low_resolution_images[index], high_resolution_images[index], img,\n",
        "                        path=\"/content/gdrive/MyDrive/datasets/result/gen_{}\".format(index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3464: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1827: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:706: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:709: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning:     `imread` is deprecated!\n",
            "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imread`` instead.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``skimage.transform.resize`` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``skimage.transform.resize`` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "d_loss: [0.32740015 0.39666748]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning:     `imread` is deprecated!\n",
            "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imread`` instead.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``skimage.transform.resize`` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``skimage.transform.resize`` instead.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}